{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hApCD_EWiq_G"
      },
      "source": [
        "SIGNIFICANT OCCURRENCE REPORTED WHEN <N_1>, WMS STING, OVER FLEW <N_2>, HAWKER BEECHCRAFT BE36, AND LANDED RUNWAY 36 DENTON, TX 12/31 1527C.  CLOSEST PROXIMITY NOT REPORTED.  \n",
        "\n",
        "AIRCRAFT OVERFLEW ANOTHER AIRCRAFT OR VEHICLE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qej1zOOTiq_f"
      },
      "source": [
        "NMAC REPORTED WHEN <C_a>, B748, AND <C_b>, B744, CAME WITHIN 300 FEET VERTICAL .36 MILE LATERAL SEPN AT 3,300 FEET 12 E LOS ANGELES, CA 12/29 1342P.  \n",
        "\n",
        "NEAR COLLISION BETWEEN AIRCRAFT AND ANOTHER AIRCRAFT OR VEHICLE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqJcN1QXiq_g"
      },
      "source": [
        "<C_a>, PIPER PA31, DESCENDED 700 FEET BELOW ASSIGNED ALTITUDE OF 4,000 FEET 13 S FAIRBANKS, AK 12/17 1233L. NO CONFLICTS REPORTED.  \n",
        "\n",
        "DESCENDED BELOW ASSIGNED/PUBLISHED ALTITUDE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKdHcnBZiq_h"
      },
      "source": [
        "<M_1>, CESSNA C208, FAILED TO MAINTAIN TWO WAY COMMUNICATION AT 8,000 FEET 28 NE BIMINI, BAHAMAS 12/29 1612L. NO CONFLICTS REPORTED. \n",
        "\n",
        "FAILED TO MAINTAIN COMMUNICATION"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUdAGml6knZ2",
        "outputId": "97dcc9de-e28e-42dc-fd1c-c322abe41e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juYWb3921r0A",
        "outputId": "1ac79c29-af38-434a-d25b-cd5315b68fff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score, hamming_loss\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9_2jpQXKqm0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "3301c3bd-62eb-4f8f-9213-481c49c97eb5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-575da76f44d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mflightData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/UCRIVERSIDE_20220617 (1).xlsx - EVENTS.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mflightData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#df = flightData.copy(deep=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/UCRIVERSIDE_20220617 (1).xlsx - EVENTS.csv'"
          ]
        }
      ],
      "source": [
        "flightData = pd.read_csv('/content/drive/MyDrive/UCRIVERSIDE_20220617 (1).xlsx - EVENTS.csv')\n",
        "flightData.head()\n",
        "\n",
        "#df = flightData.copy(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJ1UzrjtQm0f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import re\n",
        "narratives = flightData['NARRATIVE REDACTED']\n",
        "\n",
        "# Remove all tags from narratives\n",
        "narratives = [re.sub(r'<(.+?)>','',narrative) for narrative in narratives]\n",
        "flightData['NARRATIVE REDACTED'] = narratives\n",
        "flightData"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = flightData.drop(flightData.iloc[:, 0:8], axis=1)\n",
        "df2"
      ],
      "metadata": {
        "id": "XOxbL0FYkVFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories = list(df2.columns.values)"
      ],
      "metadata": {
        "id": "hhfNn1JTkeRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNWUivYvO6YS"
      },
      "outputs": [],
      "source": [
        "# X = flightData['NARRATIVE REDACTED'] \n",
        "# Y = flightData.iloc[:, 8:]\n",
        "\n",
        "# x_train, x_test, y_train, y_test = train_test_split(X, Y, \n",
        "#                                                     random_state=42, \n",
        "#                                                     test_size=0.2,\n",
        "#                                                     shuffle=True)\n",
        "\n",
        "# print('Training on {} examples with {} corresponding labels.'.format(x_train.shape, y_train.shape))\n",
        "# print('Testing on', x_test.shape, 'examples with', y_test.shape, 'corresponding labels.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aPymDw8irAU"
      },
      "outputs": [],
      "source": [
        "# x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGYu59MzirAX"
      },
      "outputs": [],
      "source": [
        "# y_test.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def word_scorer(w1, w2 = None, with_similarity_score = False):\n",
        "    '''\n",
        "    Retrive the list of wordnet synonyms for a given word, and it's definition. Scores each against one specific synset.\n",
        "    \n",
        "    Args:\n",
        "    w1 = word, text string, 'code'\n",
        "    w2 = defined synset for similarity comparison, e.g. 'code.v.01' (default = None)\n",
        "    with_similarity_score = set to True to include similarity scores of w1 with w2 synsets (default = False)\n",
        "    \n",
        "    Outputs:\n",
        "    list of tuples (synonym name, synonym definition, similarity score)\n",
        "    '''\n",
        "\n",
        "    syns = []\n",
        "    for i in range(len(wordnet.synsets(w1))):\n",
        "        if with_similarity_score:\n",
        "            if w2 is not None:\n",
        "                syns.append((wordnet.synsets(w1)[i].name(),\n",
        "                             wordnet.synsets(w1)[i].definition(),\n",
        "                             wordnet.synset(w2).wup_similarity(wordnet.synsets(w1)[i])))\n",
        "            else:\n",
        "                print('with_similarity_score set to True, but no w2 defined')\n",
        "                break\n",
        "        else:\n",
        "            syns.append((wordnet.synsets(w1)[i].name(),\n",
        "                         wordnet.synsets(w1)[i].definition()))\n",
        "    return syns"
      ],
      "metadata": {
        "id": "zWcnPL-alizu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_phrase(phrase):\n",
        "    '''\n",
        "    Removes stopwords, punctuation from text, and converts into a list of word tokens\n",
        "    \n",
        "    Args:\n",
        "    phrase = text string\n",
        "    \n",
        "    Outputs:\n",
        "    list of word tokens\n",
        "    '''\n",
        "    \n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    word_tokens = word_tokenize(phrase)\n",
        "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
        "    return filtered_sentence"
      ],
      "metadata": {
        "id": "R-r3em20z9xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def topic_scorer(phrase, topic, sim_thresh = 0.6, return_hits = False):\n",
        "    '''\n",
        "    For each word in a sentence, retrieves the synonym set. For each synonym we measure the wup_similarity\n",
        "    to the topic at hand. If similarity > sim_threshold, the topic is said to have been mentioned.\n",
        "    The wup_similarity threshold can be configured: where a higher threshold for increases the strictness of the word-to-topic similarity condition.\n",
        "    If return_hits is set to True, the words in the phrase that were mapped to each topic will be returned.\n",
        "    \n",
        "    Args:\n",
        "    filtered_sentence = tokenized sentence, preferrably stripped of stopwords\n",
        "    topic = synset of the topic in question.\n",
        "    sim_thresh = wup_similarity threshold for word and topic to be deemed similar enough (default 0.6)\n",
        "    return_hits = return the words that matched to each topic (default = False)\n",
        "    \n",
        "    Outputs:\n",
        "    Integer count of the number of mentions of the topic in the filtered_sentence\n",
        "    '''\n",
        "    \n",
        "    phrase = prep_phrase(phrase)\n",
        "    word_scores = []\n",
        "    \n",
        "    for w in range(len(phrase)):\n",
        "        syns = wordnet.synsets(phrase[w])\n",
        "        syns_sim = [topic.wup_similarity(syns[synonym]) for synonym in range(len(syns))]\n",
        "        syns_sim = [sim if sim is not None else 0 for sim in syns_sim]\n",
        "        try:\n",
        "            syns_sim = np.max([1 if sim > sim_thresh else 0 for sim in syns_sim])\n",
        "        except ValueError:\n",
        "            syns_sim = 0\n",
        "        word_scores.append(syns_sim)\n",
        "    hits = [phrase[w] for w in range(len(phrase)) if word_scores[w] == 1]\n",
        "        \n",
        "    if return_hits:    \n",
        "        return (np.sum(word_scores), hits)\n",
        "    else:\n",
        "        return np.sum(word_scores)"
      ],
      "metadata": {
        "id": "CkIbG8eR0JZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_topic_scorer(phrase, topic_dictionary, sim_thresh=0.6, return_hits=False):\n",
        "    '''\n",
        "    Takes a passage of text and maps words in that text to topics that have been defined in a topic dictionary.\n",
        "    The wup_similarity threshold can be configured: where a higher threshold for increases the strictness of the word-to-topic similarity condition.\n",
        "    If return_hits is set to True, the words in the phrase that were mapped to each topic will be returned.\n",
        "    \n",
        "    Args:\n",
        "    phrase = passage of text\n",
        "    topic_dictionary = dictionary where key:value is reader-friendly topic name:assigned synonym in wordnet\n",
        "    sim_thresh = wup_similarity threshold for word and topic to be deemed similar enough (default 0.6)\n",
        "    return_hits = return the words that matched to each topic (default = False)\n",
        "    \n",
        "    Outputs:\n",
        "    sim_scores = dictionary where key:value is the reader-friendly topic name:number of synonyms present in the text\n",
        "    '''\n",
        "\n",
        "    sim_scores = {}\n",
        "    \n",
        "    for topic in list(topic_dictionary.keys()):\n",
        "        \n",
        "        for syn in topic_dictionary[topic]:\n",
        "            topic_synset = wordnet.synset(syn)\n",
        "\n",
        "            if topic in sim_scores.keys():\n",
        "                sim_scores[topic] += topic_scorer(phrase, topic_synset, sim_thresh, return_hits)\n",
        "            else:\n",
        "                sim_scores[topic] = topic_scorer(phrase, topic_synset, sim_thresh, return_hits)\n",
        "    \n",
        "    return sim_scores"
      ],
      "metadata": {
        "id": "gbmMvqCT0Kin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# topic_dictionary = {\n",
        "#     '1 AIRCRAFT DEPARTING, 1 AIRCRAFT CROSSING OR EXITING SAME RUNWAY': ['depart.v.03', 'depart.v.04', 'same.a.01', 'same.a.02'],\n",
        "#     '1 AIRCRAFT LANDING, 1 AIRCRAFT CROSSING OR EXITING SAME RUNWAY': ['landing.n.03', 'same.a.01', 'same.a.02', 'cross.v.06'],\n",
        "#     '1 AIRCRAFT LANDING, 1 AIRCRAFT DEPARTING INTERSECTING RUNWAYS': ['landing.n.03', 'depart.v.03', 'depart.v.04'],\n",
        "#     '1 AIRCRAFT LANDING, 1 AIRCRAFT DEPARTING SAME RUNWAY': ['landing.n.03', 'depart.v.03', 'depart.v.04', 'same.a.01', 'same.a.02'],\n",
        "#     '2 AIRCRAFT LANDING,  SAME RUNWAY': ['landing.n.03', 'same.a.01', 'same.a.02', 'both.s.01', 'final.s.02'],\n",
        "#     'ABORTED TAKEOFF': ['abort.n.01', 'abort.v.01', 'stop.n.02', 'stop.v.01'],\n",
        "#     'ACCEPTED DEPARTURE CLEARANCE MEANT FOR ANOTHER AIRCRAFT': ['depart.v.03', 'depart.v.04', 'accept.v.03', 'accept.v.04', 'another.s.01'],\n",
        "#     'ACCEPTED LUAW MEANT FOR ANOTHER AIRCRAFT': ['accept.v.03', 'accept.v.04', 'intend.v.01', 'line_up.v.03', 'wait.n.02', 'wait.v.01', 'wait.v.02'],\n",
        "#     'ACCEPTED/TOOK CLEARANCE/INSTRUCTION MEANT FOR ANOTHER AIRCRAFT': ['accept.v.03', 'accept.v.04', 'intend.v.01', 'take.v.09', 'take.v.27', 'clearance.n.03'],\n",
        "#     'ACCEPTED/TOOK DEPARTURE CLEARANCE INTENDED FOR ANOTHER AIRCRAFT': ['accept.v.03', 'accept.v.04', 'intend.v.01', 'take.v.09', 'take.v.27', 'clearance.n.03', 'depart.v.03', 'depart.v.04', 'takeoff.n.01', 'takeoff.n.02'],\n",
        "#     'ACCEPTED/TOOK DESCENT CLEARANCE INTENDED FOR ANOTHER AIRCRAFT': ['accept.v.03', 'accept.v.04', 'intend.v.01', 'take.v.09', 'take.v.27', 'clearance.n.03', 'descent.n.01', 'descent.n.03'],\n",
        "#     'AIRCRAFT ATTEMPTED TO LAND ON CLOSED RUNWAY': ['low.r.01', 'low.a.02', 'closed.a.01', 'closed.s.09'],\n",
        "#     'AIRCRAFT CLEARED FOR LOW APPROACH, PERFORMED TOUCH AND GO': ['touch.v.08', 'go.v.03'],\n",
        "#     'AIRCRAFT CLEARED TO DEPART RUNWAY, ATTEMPTED TO DEPART TAXIWAY': ['depart.v.03', 'depart.v.04', 'cancel.v.01', 'stop.v.01', 'taxiway.n.01'],\n",
        "#     'AIRCRAFT CLEARED TO LAND ON RUNWAY, LANDED ON TAXIWAY': ['land.v.02', 'taxiway.n.01'],\n",
        "#     'AIRCRAFT CLEARED TO LAND, PERFORMED TOUCH AND GO': ['land.v.02', 'touch.v.08', 'go.v.03'],\n",
        "#     'AIRCRAFT FIRE': ['fire.n.01', 'fire.n.03', 'burn.v.01'],\n",
        "#     'AIRCRAFT MANEUVERED (AIRBORNE/SURFACE TO AVOID ANOTHER AIRCRAFT OR VEHICLE': ['avoid.v.01'],\n",
        "#     'AIRCRAFT OVERFLEW ANOTHER AIRCRAFT OR VEHICLE': ['pass_over.v.04'],\n",
        "    # 'ATC CANCELED DEPARTURE CLEARANCE',\n",
        "    # 'ATC DID NOT ISSUE TRAFFIC ADVISORY',\n",
        "    # 'ATC INSTRUCTED AIRCRAFT TO GO AROUND',\n",
        "    # 'ATC INSTRUCTED AIRCRAFT/VEHICLE TO HOLD SHORT',\n",
        "    # 'ATC ISSUED TRAFFIC ADVISORY',\n",
        "    # 'ATC USED INCORRECT CALLSIGN',\n",
        "    # 'ATTEMPTED TO DEPART WITHOUT CLEARANCE',\n",
        "    # 'ATTEMPTED TO DEPART WRONG RUNWAY',\n",
        "    # 'ATTEMPTED TO LAND ON WRONG RUNWAY',\n",
        "    # 'CARELESS, RECKLESS, OR DANGEROUS ACTION',\n",
        "    # 'CHANGED FREQUENCY WITHOUT AUTHORIZATION',\n",
        "    # 'CLEARED TO DEPART RUNWAY, ATTEMPTED TO DEPART TAXIWAY',\n",
        "    # 'CLEARED TO LAND, PERFORMED TOUCH AND GO',\n",
        "    # 'CLIMBED ABOVE ASSIGNED/PUBLISHED ALTITUDE',\n",
        "    # 'CLIMBED ABOVE CROSSING RESTRICTION ALTITUDE',\n",
        "    # 'COLLISION BETWEEN AIRCRAFT AND ANOTHER AIRCRAFT OR VEHICLE',\n",
        "    # 'COLLISION WITH TERRAIN, OBSTACLES',\n",
        "    # 'CROP DUSTING, AERIAL APPLICATION',\n",
        "    # 'CROSSED RUNWAY HOLD LINE WITHOUT CLEARANCE',\n",
        "    # 'DEPARTED FROM CLOSED RUNWAY',\n",
        "    # 'DEPARTED FROM RUNWAY WITHOUT CLEARANCE',\n",
        "    # 'DEPARTED FROM TAXIWAY WITHOUT CLEARANCE',\n",
        "    # 'DEPARTED RAMP WITHOUT AUTHORIZATION',\n",
        "    # 'DEPARTED WITHOUT CLEARANCE/AUTHORIZATION',\n",
        "    # 'DEPARTED WITHOUT IFR CLEARANCE',\n",
        "    # 'DEPARTED WITHOUT IFR RELEASE',\n",
        "    # 'DEPARTED WITHOUT RELEASE CLEARANCE',\n",
        "    # 'DEPARTED WRONG RUNWAY',\n",
        "    # 'DESCENDED BELOW ASSIGNED/PUBLISHED ALTITUDE',\n",
        "    # 'DESCENDED BELOW CROSSING RESTRICTION ALTITUDE',\n",
        "    # 'ENTERED AIRSPACE WITHOUT AUTHORIZATION',\n",
        "    # 'ENTERED MOVEMENT AREA WITHOUT CLEARANCE',\n",
        "    # 'ENTERED RUNWAY SAFETY AREA WITHOUT CLEARANCE',\n",
        "    # 'ENTERED SFRA WITHOUT AUTHORIZATION',\n",
        "    # 'ENTERED SPECIAL USE AIRSPACE WITHOUT AUTHORIZATION',\n",
        "    # 'ENTERED/CROSSED CLOSED RUNWAY WITHOUT CLEARANCE',\n",
        "    # 'ENTERED/CROSSED RUNWAY WITHOUT CLEARANCE',\n",
        "    # 'ENTERED/CROSSED TAXIWAY WITHOUT CLEARANCE',\n",
        "    # 'EXECUTED TOUCH AND GO WITHOUT CLEARANCE',\n",
        "    # 'EXIT SPECIAL USE AIRSPACE WITHOUT CLEARANCE (SPILL OUT)',\n",
        "    # 'FAILED TO CLEAR HOLD LINE',\n",
        "    # 'FAILED TO CLEAR RUNWAY',\n",
        "    # 'FAILED TO CLEAR RUNWAY SAFETY AREA',\n",
        "    # 'FAILED TO CLIMB TO ASSIGNED/PUBLISHED ALTITUDE',\n",
        "    # 'FAILED TO CLOSE/CANCEL IFR FLIGHT PLAN',\n",
        "    # 'FAILED TO COMPLY WITH CROSSING RESTRICTION',\n",
        "    # 'FAILED TO DESCEND TO MEET CROSSING RESTRICTION',\n",
        "    # 'FAILED TO ESTABLISH COMMUNICATION',\n",
        "    # 'FAILED TO EXIT/CLEAR RUNWAY',\n",
        "    # 'FAILED TO FLY ASSIGNED AIRSPEED',\n",
        "    # 'FAILED TO FLY ASSIGNED ALTITUDE',\n",
        "    # 'FAILED TO FLY ASSIGNED APPROACH',\n",
        "    # 'FAILED TO FLY ASSIGNED APPROACH COURSE',\n",
        "    # 'FAILED TO FLY ASSIGNED ARRIVAL ROUTE',\n",
        "    # 'FAILED TO FLY ASSIGNED/PUBLISHED APPROACH/ARRIVAL CLEARANCE/PROCEDURE',\n",
        "    # 'FAILED TO FLY ASSIGNED/PUBLISHED ARRIVAL CLEARANCE/PROCEDURE',\n",
        "    # 'FAILED TO FLY ASSIGNED/PUBLISHED MISSED APPROACH',\n",
        "    # 'FAILED TO FLY/FOLLOW ASSIGNED COURSE/CLEARANCE/heading',\n",
        "    # 'FAILED TO FOLLOW TAXI INSTRUCTIONS',\n",
        "    # 'FAILED TO FOLLOW/FLY ASSIGNED/PUBLISHED DEPARTURE INSTRUCTIONS/CLEARANCE',\n",
        "    # 'FAILED TO FOLLOW/FLY DEPARTURE PROCEDURE',\n",
        "    # 'FAILED TO MAINTAIN COMMUNICATION',\n",
        "    # 'FAILED TO MEET CROSSING RESTRICTION ALTITUDE',\n",
        "    # 'FLIGHT BELOW OR DESCENDED BELOW MINIMUM VECTOR ALTITUDE (MVA)',\n",
        "    # 'GO AROUND',\n",
        "    # 'ILLNESS, INJURY',\n",
        "    # 'LANDED  WITHOUT CLEARANCE',\n",
        "    # 'LANDED CLOSED AIRPORT',\n",
        "    # 'LANDED ON CLOSED RUNWAY',\n",
        "    # 'LANDED ON TAXIWAY',\n",
        "    # 'LANDED ON TAXIWAY WITHOUT CLEARANCE',\n",
        "    # 'LANDED RUNWAY WITHOUT CLEARANCE',\n",
        "    # 'LANDED WITHOUT CLEARANCE',\n",
        "    # 'LANDED WRONG AIRPORT',\n",
        "    # 'LANDED WRONG RUNWAY',\n",
        "    # 'LASER',\n",
        "    # 'LINED UP TO LAND ON TAXIWAY',\n",
        "    # 'LINED UP TO LAND WRONG RUNWAY',\n",
        "    # 'LOSS OF SEPARATION',\n",
        "    # 'LOSS OF SEPARATION WITH TERRAIN, OBSTACLES',\n",
        "    # 'LUAW': ['line_up.v.03', 'wait.n.02', 'wait.v.01', 'wait.v.02'],\n",
        "    # 'LUAW WRONG RUNWAY': [],\n",
        "    # 'MIDAIR COLLISION',\n",
        "    # 'MILITARY OPERATIONS',\n",
        "    # 'MISSED APPROACH',\n",
        "    # 'NEAR COLLISION BETWEEN AIRCRAFT AND ANOTHER AIRCRAFT OR VEHICLE',\n",
        "    # 'OVERFLEW AIRCRAFT ON RUNWAY',\n",
        "    # 'PARACHUTE MISHAP',\n",
        "    # 'PARACHUTE/SKY DIVING OPERATIONS',\n",
        "    # 'PARALLEL RUNWAYS',\n",
        "    # 'RUNWAY INCURSION',\n",
        "    # 'SPACE VEHICLE, FACILITY?',\n",
        "    # 'TAXI WITHOUT CLEARANCE',\n",
        "    # 'TAXIED ON CLOSED TAXIWAY WITHOUT CLEARANCE',\n",
        "    # 'TAXIED TO PARKING WITHOUT CLEARANCE',\n",
        "    # 'TAXIED TO RUNWAY WITHOUT CLEARANCE',\n",
        "    # 'TCAS ALERT / RA',\n",
        "    # 'TCAS RA',\n",
        "    # 'TOUCH AND GO WRONG RUNWAY',\n",
        "    # 'TRAINING IN PROGRESS',\n",
        "    # 'TURBULENCE',\n",
        "    # 'UNMANNED AIRCRAFT SYSTEM',\n",
        "    # 'VEHICLE ON RUNWAY WITHOUT AUTHORIZATION',\n",
        "    # 'WAKE TURBULENCE',\n",
        "    # 'WORKLOAD, DISTRACTION': []\n",
        "# }"
      ],
      "metadata": {
        "id": "zcXOjMOAJ02S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# topic_dictionary = {\n",
        "#     '1 AIRCRAFT DEPARTING, 1 AIRCRAFT CROSSING OR EXITING SAME RUNWAY': 'depart.v.03',\n",
        "#     '1 AIRCRAFT LANDING, 1 AIRCRAFT CROSSING OR EXITING SAME RUNWAY': 'landing.n.03',\n",
        "#     '1 AIRCRAFT LANDING, 1 AIRCRAFT DEPARTING INTERSECTING RUNWAYS': 'landing.n.03',\n",
        "#     '1 AIRCRAFT LANDING, 1 AIRCRAFT DEPARTING SAME RUNWAY': 'same.a.01',\n",
        "#     '2 AIRCRAFT LANDING,  SAME RUNWAY': 'both.s.01',\n",
        "#     'ABORTED TAKEOFF': 'abort.n.01',\n",
        "#     'ACCEPTED DEPARTURE CLEARANCE MEANT FOR ANOTHER AIRCRAFT': 'another.s.01',\n",
        "#     'ACCEPTED LUAW MEANT FOR ANOTHER AIRCRAFT': 'line_up.v.03',\n",
        "#     'ACCEPTED/TOOK CLEARANCE/INSTRUCTION MEANT FOR ANOTHER AIRCRAFT': 'clearance.n.03',\n",
        "#     'ACCEPTED/TOOK DEPARTURE CLEARANCE INTENDED FOR ANOTHER AIRCRAFT': 'takeoff.n.02',\n",
        "#     'ACCEPTED/TOOK DESCENT CLEARANCE INTENDED FOR ANOTHER AIRCRAFT': 'descent.n.03',\n",
        "#     'AIRCRAFT ATTEMPTED TO LAND ON CLOSED RUNWAY': 'closed.s.09',\n",
        "#     'AIRCRAFT CLEARED FOR LOW APPROACH, PERFORMED TOUCH AND GO': 'touch.v.08',\n",
        "#     'AIRCRAFT CLEARED TO DEPART RUNWAY, ATTEMPTED TO DEPART TAXIWAY': 'taxiway.n.01',\n",
        "#     'AIRCRAFT CLEARED TO LAND ON RUNWAY, LANDED ON TAXIWAY': 'land.v.02',\n",
        "#     'AIRCRAFT CLEARED TO LAND, PERFORMED TOUCH AND GO': 'touch.v.08',\n",
        "#     'AIRCRAFT FIRE': 'fire.n.01',\n",
        "#     'AIRCRAFT MANEUVERED (AIRBORNE/SURFACE TO AVOID ANOTHER AIRCRAFT OR VEHICLE': 'avoid.v.01',\n",
        "#     'AIRCRAFT OVERFLEW ANOTHER AIRCRAFT OR VEHICLE': 'pass_over.v.04',\n",
        "#     'ILLNESS, INJURY': 'injury.n.02'\n",
        "# }"
      ],
      "metadata": {
        "id": "8Zw0sfDa9PFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_scorer('two')"
      ],
      "metadata": {
        "id": "X3REC6wMoV6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_dictionary = {\n",
        "    'AIRCRAFT MANEUVERED (AIRBORNE/SURFACE TO AVOID ANOTHER AIRCRAFT OR VEHICLE': ['avoid.v.01'],\n",
        "    'ATC CANCELED DEPARTURE CLEARANCE': ['cancel.v.01', 'clearance.n.03'],\n",
        "    'ATC INSTRUCTED AIRCRAFT TO GO AROUND': ['around.r.07'],\n",
        "    'CLIMBED ABOVE ASSIGNED/PUBLISHED ALTITUDE': ['climb.v.01', 'above.r.02', 'assigned.a.01', 'altitude.n.01'],\n",
        "    'CROSSED RUNWAY HOLD LINE WITHOUT CLEARANCE': ['cross.v.05', 'line.n.11', 'clearance.n.03'],\n",
        "    'DEPARTED WITHOUT CLEARANCE/AUTHORIZATION': ['depart.v.03', 'clearance.n.03'],\n",
        "    'DESCENDED BELOW ASSIGNED/PUBLISHED ALTITUDE': ['descend.v.01', 'below.r.01', 'assigned.a.01', 'altitude.n.01'],\n",
        "    'ENTERED AIRSPACE WITHOUT AUTHORIZATION': ['enter.v.01', 'airspace.n.01'],\n",
        "    'ENTERED/CROSSED RUNWAY WITHOUT CLEARANCE': ['enter.v.01', 'runway.n.04', 'clearance.n.03'],\n",
        "    'ENTERED/CROSSED TAXIWAY WITHOUT CLEARANCE': ['enter.v.01', 'taxiway.n.01', 'clearance.n.03'],\n",
        "    'FAILED TO COMPLY WITH CROSSING RESTRICTION': ['fail.v.01', 'cross.v.05', 'restriction.n.03'],\n",
        "    'FAILED TO FLY/FOLLOW ASSIGNED COURSE/CLEARANCE/heading': ['fail.v.01', 'assigned.a.01'],\n",
        "    'FAILED TO FOLLOW TAXI INSTRUCTIONS': ['fail.v.01', 'taxi.v.01'],\n",
        "    'FAILED TO FOLLOW/FLY DEPARTURE PROCEDURE': ['fail.v.01', 'depart.v.03'],\n",
        "    'FAILED TO MAINTAIN COMMUNICATION': ['fail.v.01', 'two.s.01'],\n",
        "    'ILLNESS, INJURY': ['fatal.a.01', 'dead.n.01', 'unresponsive.a.01', 'hospital.n.02', 'ill.a.01', 'injure.v.01', 'stroke.n.03', 'blur.v.02', 'pain.n.03', 'crash.v.03', 'cardiac.a.01', 'suffer.v.02'],\n",
        "    'LANDED WITHOUT CLEARANCE': ['land.v.02', 'clearance.n.03'],\n",
        "    'SPACE VEHICLE, FACILITY?': ['national_aeronautics_and_space_administration.n.01', 'shuttle.n.02'],\n",
        "    'UNIDENTIFIED': ['unidentified.s.01'],\n",
        "    'VEHICLE ON RUNWAY WITHOUT AUTHORIZATION': ['vehicle.n.01', 'authorization.n.04']\n",
        "}"
      ],
      "metadata": {
        "id": "QnMfl3j29ne0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tempsubset = flightData.loc[(flightData.loc[:, categories[0:18]] != 0).any(axis=1)]\n",
        "#tempsubset"
      ],
      "metadata": {
        "id": "g_f4DHrQw7FQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for index, row in flightData.iloc[2817:2818, :].iterrows():\n",
        "print(multi_topic_scorer(flight['NARRATIVE REDACTED'][5], topic_dictionary, sim_thresh=0.7, return_hits=True))"
      ],
      "metadata": {
        "id": "-S8ynTiz0NFs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "MultiClassificationFresh.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}